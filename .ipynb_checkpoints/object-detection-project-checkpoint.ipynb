{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARGUS: Object Detection with YOLO in PyTorch\n",
    "\n",
    "## Pre-requistes\n",
    "Lets ensure the required libraries are installed and resources are ready to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch\n",
    "!pip install https://download.pytorch.org/whl/cpu/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenCV\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and convert YOLO V3 Weights * May take a while\n",
    "!wget https://pjreddie.com/media/files/yolov3.weights -O ~/yolov3.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Weights into a PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yolo_pytorch.models as models\n",
    "from yolo_pytorch.utils.utils import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Seting up the model\n",
    "model_config = 'yolo_pytorch/yolov3.cfg'\n",
    "img_size = 416\n",
    "weights = os.path.join(os.path.expanduser(\"~\"), \"yolov3.weights\")\n",
    "\n",
    "model = models.Darknet(model_config, img_size)\n",
    "models.load_darknet_weights(model, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Existing Files From Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "    \n",
    "def delete_folder_contents(folder_url):\n",
    "    for filename in os.listdir(folder_url):\n",
    "        file_path = os.path.join(folder_url, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "    print('Files have been successfully deleted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting the Amount of Object in an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(model, img):\n",
    "    \n",
    "    # Use GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        Tensor = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        Tensor = torch.FloatTensor\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Get scaled width and height\n",
    "    ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
    "    imw = round(img.size[0] * ratio)\n",
    "    imh = round(img.size[1] * ratio)\n",
    "\n",
    "    # Transform the image for prediction\n",
    "    img_transforms = transforms.Compose([\n",
    "         transforms.Resize((imh, imw)),\n",
    "         transforms.Pad((max(int((imh-imw)/2),0), max(int((imw-imh)/2),0), max(int((imh-imw)/2),0), max(int((imw-imh)/2),0)),\n",
    "                        (128,128,128)),\n",
    "         transforms.ToTensor(),\n",
    "         ])\n",
    "    \n",
    "    # convert image to a Tensor\n",
    "    image_tensor = img_transforms(img).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    \n",
    "    # Use the model to detect objects in the image\n",
    "    with torch.no_grad():\n",
    "        detections = model(image_tensor)\n",
    "        # Eliminate duplicates with non-max suppression\n",
    "        detections = non_max_suppression(detections, 0.8, 0.4)\n",
    "    return detections[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying a Rectangle and Name around Objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_objects(img, detections, image_name):\n",
    "    import random\n",
    "    import matplotlib.patches as patches\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Get bounding-box colors\n",
    "    cmap = plt.get_cmap('tab20b')\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, 20)]\n",
    "\n",
    "    img = np.array(img)\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(1, figsize=(12,9))\n",
    "    ax.imshow(img)\n",
    "\n",
    "    pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
    "    pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
    "    unpad_h = img_size - pad_y\n",
    "    unpad_w = img_size - pad_x\n",
    "\n",
    "    # clean up\n",
    "    delete_folder_contents('data/object_detection_processed/')\n",
    "    \n",
    "    if detections is not None:\n",
    "        # process each instance of each class that was found\n",
    "        classes = load_classes('yolo_pytorch/coco.names')\n",
    "        unique_labels = detections[:, -1].cpu().unique()\n",
    "        n_cls_preds = len(unique_labels)\n",
    "        bbox_colors = random.sample(colors, n_cls_preds)\n",
    "        # browse detections and draw bounding boxes\n",
    "        for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
    "            # Get the class name\n",
    "            predicted_class = classes[int(cls_pred)]\n",
    "            \n",
    "            # We'll display the class name and probability\n",
    "            label = '{} {:.2f}'.format(predicted_class, cls_conf)\n",
    "            \n",
    "            # Set the box dimensions\n",
    "            box_h = ((y2 - y1) / unpad_h) * img.shape[0]\n",
    "            box_w = ((x2 - x1) / unpad_w) * img.shape[1]\n",
    "            y1 = ((y1 - pad_y // 2) / unpad_h) * img.shape[0]\n",
    "            x1 = ((x1 - pad_x // 2) / unpad_w) * img.shape[1]\n",
    "            \n",
    "            # Add a box with the color for this class\n",
    "            color = bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])]\n",
    "            bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor='none')\n",
    "            ax.add_patch(bbox)\n",
    "            plt.text(x1, y1, s=label, color='white', verticalalignment='top',\n",
    "                    bbox={'color': color, 'pad': 0})\n",
    "            _file = 'data/object_detection_processed/processed_image_' + image_name\n",
    "            plt.savefig(_file)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing all the images in a specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image as img\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def analyse_images(source):\n",
    "    if os.path.isfile(source + '.DS_Store'):\n",
    "        os.remove(source + '.DS_Store')\n",
    "        \n",
    "    for image_file in os.listdir(source):\n",
    "\n",
    "        # Load image\n",
    "        img_path = os.path.join(source, image_file)\n",
    "        image = img.open(img_path)\n",
    "\n",
    "        # Detect objects in the image\n",
    "        detections = detect_objects(model, image)\n",
    "\n",
    "        # Original Image\n",
    "        # display(Image(filename=source + image_file))\n",
    "\n",
    "        # Display the image with bounding boxes\n",
    "        show_objects(image, detections, image_file)\n",
    "\n",
    "    print('Analysis Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Video Frames Into Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries \n",
    "import cv2 \n",
    "import os \n",
    "  \n",
    "def convert_video_into_frames(video_src, save_to_folder_path):\n",
    "    # Read the video from specified path \n",
    "    cam = cv2.VideoCapture(video_src) \n",
    "\n",
    "    try: \n",
    "        # creating a folder named data \n",
    "        if not os.path.exists('data'): \n",
    "            os.makedirs('data') \n",
    "\n",
    "    # if not created then raise error \n",
    "    except OSError: \n",
    "        print ('Error: Creating directory of data') \n",
    "\n",
    "    # frame \n",
    "    currentframe = 0\n",
    "\n",
    "    # clean up\n",
    "    delete_folder_contents(save_to_folder_path)\n",
    "    \n",
    "    while(True): \n",
    "\n",
    "        # reading from frame \n",
    "        ret,frame = cam.read() \n",
    "\n",
    "        if ret: \n",
    "            # if video is still left continue creating images \n",
    "            name = save_to_folder_path + str(currentframe) + '.jpg'\n",
    "            print ('Creating...' + name) \n",
    "\n",
    "            # writing the extracted images \n",
    "            cv2.imwrite(name, frame) \n",
    "\n",
    "            # increasing counter so that it will \n",
    "            # show how many frames are created \n",
    "            currentframe += 1\n",
    "        else: \n",
    "            break\n",
    "\n",
    "    # Release all space and windows once done \n",
    "    cam.release() \n",
    "    cv2.destroyAllWindows() \n",
    "    \n",
    "    print(\"Video Frames Successfully Converted to Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Video from all the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def create_video(image_folder_src, video_name, fps):\n",
    "    video_url = 'data/object_detection_video/' + video_name + '.avi'\n",
    "\n",
    "    images = [img for img in os.listdir(image_folder_src) if img.endswith(\".jpg\")]\n",
    "    frame = cv2.imread(os.path.join(image_folder_src, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    video = cv2.VideoWriter(video_url, 0, fps, (width,height))\n",
    "\n",
    "    for image in images:\n",
    "        video.write(cv2.imread(os.path.join(image_folder_src, image)))\n",
    "\n",
    "        # Original Image\n",
    "        # display(Image(filename=image_folder + \"/\"+ image))\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "    \n",
    "    print(\"Video has succesfully been created.\\n Path: \" + video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video('data/object_detection_processed', video_name + \"_processed_od\", slow_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(video_name, file_type):\n",
    "    convert_video_into_frames('data/object_detection_video/' + video_name + file_type, 'data/object_detection/')\n",
    "    analyse_images('data/object_detection/')\n",
    "                              \n",
    "    normal_speed = 25\n",
    "    slow_speed = 5\n",
    "    create_video('data/object_detection_processed', video_name + \"_processed_od\", slow_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run('street_bike', '.mp4') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
